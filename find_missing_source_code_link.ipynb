{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to find missing GH repos for advisories that are missing\n",
    "\n",
    "* Requires you to run ecosystem_identify_missing_vfc_adv.ipynb\n",
    "    * Generates: ./data/final_data/advisories_missing_GH_repo_20221204.csv\n",
    "    * Prior cell to last cell in notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import glob\n",
    "import json\n",
    "from xml.etree import ElementTree\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script to load current GHSA DB\n",
    "\n",
    "* Make sure you have the GHSA DB locally cloned\n",
    "    * set the ghsa_db_path to your cloned location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ghsa_db_path = f\"../advisory-database/advisories/github-reviewed/\"\n",
    "\n",
    "# get all JSON files\n",
    "ghsa_files = glob.glob(f\"{ghsa_db_path}*/*/*/*.json\")\n",
    "\n",
    "df_ghsa = pd.DataFrame()\n",
    "\n",
    "# load all json files to obtain the \"PACKAGE\" within the references list\n",
    "for index, file in enumerate(ghsa_files):\n",
    "    # placeholders for GHSA Info\n",
    "    id = None\n",
    "    package_ecosystem = None\n",
    "    package_name = None\n",
    "    references_package = None\n",
    "    \n",
    "    with open(file, 'r') as f:\n",
    "        # load JSON\n",
    "        temp_file = json.load(f)\n",
    "        \n",
    "        # set GHSA info\n",
    "        id = temp_file['id']\n",
    "        package_ecosystem = temp_file[\"affected\"][0][\"package\"][\"ecosystem\"]\n",
    "        package_name = temp_file[\"affected\"][0][\"package\"][\"name\"]\n",
    "        \n",
    "        # check each reference for the package (source code) url\n",
    "        for temp_ref in temp_file[\"references\"]:\n",
    "            if temp_ref[\"type\"] == \"PACKAGE\":\n",
    "                references_package = temp_ref[\"url\"]\n",
    "        \n",
    "        # append to df_ghsa\n",
    "        df_ghsa = pd.concat([df_ghsa, pd.DataFrame([[id, package_ecosystem,\n",
    "                                                     package_name, references_package]],\n",
    "                                                   columns=[\"id\", \"package_ecosystem\",\n",
    "                                                            \"package_name\", \"references_package\"])])\n",
    "    \n",
    "        f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>package_ecosystem</th>\n",
       "      <th>package_name</th>\n",
       "      <th>references_package</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-9272-59x2-gwf2</td>\n",
       "      <td>npm</td>\n",
       "      <td>ripedm160</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-8g64-9cm2-838j</td>\n",
       "      <td>npm</td>\n",
       "      <td>bugfer-xor</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-8q2c-2396-hf7j</td>\n",
       "      <td>npm</td>\n",
       "      <td>appx-compiler</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-5mm9-55c9-p5r7</td>\n",
       "      <td>npm</td>\n",
       "      <td>mogoose</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-48hw-37g6-3gw4</td>\n",
       "      <td>npm</td>\n",
       "      <td>mx-nested-menu</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-8gc6-65mm-xr6r</td>\n",
       "      <td>npm</td>\n",
       "      <td>bp66</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-whv6-rj84-2vh2</td>\n",
       "      <td>npm</td>\n",
       "      <td>nextcloud-vue-collections</td>\n",
       "      <td>https://github.com/juliushaertl/nextcloud-vue-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-xwqw-rf2q-xmhf</td>\n",
       "      <td>npm</td>\n",
       "      <td>buefy</td>\n",
       "      <td>https://github.com/buefy/buefy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-77q4-m83q-w76v</td>\n",
       "      <td>npm</td>\n",
       "      <td>browserify-hmr</td>\n",
       "      <td>https://github.com/AgentME/browserify-hmr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-84qj-9qf2-q92r</td>\n",
       "      <td>npm</td>\n",
       "      <td>pm-controls</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-r9q4-w3fm-wrm2</td>\n",
       "      <td>npm</td>\n",
       "      <td>google-closure-library</td>\n",
       "      <td>https://github.com/google/closure-library</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-mmqv-m45h-q2hp</td>\n",
       "      <td>npm</td>\n",
       "      <td>localeval</td>\n",
       "      <td>https://github.com/espadrine/localeval</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-vxfp-qmpq-6826</td>\n",
       "      <td>npm</td>\n",
       "      <td>hpmm</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-54xj-q58h-9x57</td>\n",
       "      <td>npm</td>\n",
       "      <td>iobroker.admin</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-r2vw-jgq9-jqx2</td>\n",
       "      <td>npm</td>\n",
       "      <td>@sap-cloud-sdk/core</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-4f9m-pxwh-68hg</td>\n",
       "      <td>npm</td>\n",
       "      <td>swagger-ui</td>\n",
       "      <td>https://github.com/swagger-api/swagger-ui</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-3h99-v4qw-p2h5</td>\n",
       "      <td>npm</td>\n",
       "      <td>coinpayment</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-vm7j-4rj6-mw2p</td>\n",
       "      <td>npm</td>\n",
       "      <td>ember_cli_babe</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-435c-qcpm-wjw5</td>\n",
       "      <td>npm</td>\n",
       "      <td>fs-extar</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GHSA-qvc5-cfrr-384v</td>\n",
       "      <td>Packagist</td>\n",
       "      <td>shopware/platform</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id package_ecosystem               package_name  \\\n",
       "0  GHSA-9272-59x2-gwf2               npm                  ripedm160   \n",
       "0  GHSA-8g64-9cm2-838j               npm                 bugfer-xor   \n",
       "0  GHSA-8q2c-2396-hf7j               npm              appx-compiler   \n",
       "0  GHSA-5mm9-55c9-p5r7               npm                    mogoose   \n",
       "0  GHSA-48hw-37g6-3gw4               npm             mx-nested-menu   \n",
       "0  GHSA-8gc6-65mm-xr6r               npm                       bp66   \n",
       "0  GHSA-whv6-rj84-2vh2               npm  nextcloud-vue-collections   \n",
       "0  GHSA-xwqw-rf2q-xmhf               npm                      buefy   \n",
       "0  GHSA-77q4-m83q-w76v               npm             browserify-hmr   \n",
       "0  GHSA-84qj-9qf2-q92r               npm                pm-controls   \n",
       "0  GHSA-r9q4-w3fm-wrm2               npm     google-closure-library   \n",
       "0  GHSA-mmqv-m45h-q2hp               npm                  localeval   \n",
       "0  GHSA-vxfp-qmpq-6826               npm                       hpmm   \n",
       "0  GHSA-54xj-q58h-9x57               npm             iobroker.admin   \n",
       "0  GHSA-r2vw-jgq9-jqx2               npm        @sap-cloud-sdk/core   \n",
       "0  GHSA-4f9m-pxwh-68hg               npm                 swagger-ui   \n",
       "0  GHSA-3h99-v4qw-p2h5               npm                coinpayment   \n",
       "0  GHSA-vm7j-4rj6-mw2p               npm             ember_cli_babe   \n",
       "0  GHSA-435c-qcpm-wjw5               npm                   fs-extar   \n",
       "0  GHSA-qvc5-cfrr-384v         Packagist          shopware/platform   \n",
       "\n",
       "                                  references_package  \n",
       "0                                               None  \n",
       "0                                               None  \n",
       "0                                               None  \n",
       "0                                               None  \n",
       "0                                               None  \n",
       "0                                               None  \n",
       "0  https://github.com/juliushaertl/nextcloud-vue-...  \n",
       "0                     https://github.com/buefy/buefy  \n",
       "0          https://github.com/AgentME/browserify-hmr  \n",
       "0                                               None  \n",
       "0          https://github.com/google/closure-library  \n",
       "0             https://github.com/espadrine/localeval  \n",
       "0                                               None  \n",
       "0                                               None  \n",
       "0                                               None  \n",
       "0          https://github.com/swagger-api/swagger-ui  \n",
       "0                                               None  \n",
       "0                                               None  \n",
       "0                                               None  \n",
       "0                                               None  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ghsa.head(n=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique GHSA Advisories loaded: 10783\n",
      "GHSA with a package (source code) link: 6205\n",
      "GHSA without a package (source code) link: 4578\n",
      "\n",
      "Ecosystem breakdown of advisories missing source code link: \n",
      "npm          1711\n",
      "Maven        1364\n",
      "PyPI          467\n",
      "Packagist     337\n",
      "RubyGems      261\n",
      "Go            238\n",
      "NuGet         166\n",
      "crates.io      34\n",
      "Name: package_ecosystem, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# create a df for advisories with missing source code link\n",
    "ghsa_missing_GH_repo = df_ghsa[df_ghsa['references_package'].isna()]\n",
    "\n",
    "print(f\"Unique GHSA Advisories loaded: {df_ghsa.id.nunique()}\")\n",
    "print(f\"GHSA with a package (source code) link: {df_ghsa[df_ghsa['references_package'].notna()].id.nunique()}\")\n",
    "print(f\"GHSA without a package (source code) link: {ghsa_missing_GH_repo.id.nunique()}\\n\")\n",
    "print(f\"Ecosystem breakdown of advisories missing source code link: \\n\"\n",
    "      f\"{ghsa_missing_GH_repo.package_ecosystem.value_counts()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MAVEN Finds\n",
    "\n",
    "* API Guide from SonaType\n",
    "    * https://central.sonatype.org/search/rest-api-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maven_pom_scm_check(groupId, artifactId, latest_version):\n",
    "    \"\"\"Check for SCM in Maven POM file\n",
    "\n",
    "    Args:\n",
    "        groupId (_type_): _description_\n",
    "        artifactId (_type_): _description_\n",
    "        latest_version (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    # generate pom xml filepath from Maven search API\n",
    "    url = f\"https://search.maven.org/remotecontent?filepath={'/'.join(groupId.split('.'))}/{artifactId}/{latest_version}/{artifactId}-{latest_version}.pom\"\n",
    "    response = requests.get(url)\n",
    "    # response.close()\n",
    "    \n",
    "    # holder value for SCM repo\n",
    "    scm_repo = None\n",
    "    \n",
    "    try:\n",
    "        # parse the XML response\n",
    "        tree = ElementTree.fromstring(response.content)\n",
    "                \n",
    "        # iterate through children in tree\n",
    "        for child in tree.findall('*'):\n",
    "            # if SCM appear then set the scm_repo\n",
    "            if 'scm' in child.tag:\n",
    "                # find the child tag\n",
    "                scm_tags = tree.findall(child.tag)\n",
    "                # for each child tag\n",
    "                for scm_tags_repo in scm_tags:\n",
    "                    # find all repos in scm child tag\n",
    "                    scm_repos = scm_tags_repo.findall('*')\n",
    "                    # pull the text tag for the scm tag\n",
    "                    for repos in scm_repos:\n",
    "                        scm_repo = repos.text\n",
    "                        \n",
    "        response.close()\n",
    "        return scm_repo   \n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Failure in file request: {url} | {str(e)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maven_search(package_name):\n",
    "    \"\"\"Search for the Maven project name to see if it exists\n",
    "\n",
    "    Args:\n",
    "        package_name (_type_): _description_\n",
    "\n",
    "    Returns:\n",
    "        _type_: _description_\n",
    "    \"\"\"\n",
    "    \n",
    "    groupId = package_name.split(':')[0]\n",
    "    artifactId = package_name.split(':')[1]\n",
    "    \n",
    "    # set url\n",
    "    url = f\"https://search.maven.org/solrsearch/select?q={groupId}+AND+a:{artifactId}&rows=10&wt=json\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    response.close()\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        temp = response.json()\n",
    "        if temp[\"response\"][\"numFound\"] >= 1:\n",
    "            # print(temp[\"response\"][\"numFound\"])\n",
    "            # obtain the latestVersion so we can obtain the pom.xml file\n",
    "            for temp_response in temp['response']['docs']:\n",
    "                # make sure the id matches the package_name for the search\n",
    "                if temp_response['id'] == package_name:\n",
    "                    latestVersion = temp_response['latestVersion']\n",
    "    \n",
    "                    # get pom.xml file\n",
    "                    temp_scm_repo = maven_pom_scm_check(groupId, artifactId, latestVersion)\n",
    "                    \n",
    "                    # print(f\"{package_name} | repo={temp_scm_repo}\")\n",
    "                    \n",
    "                    return temp_scm_repo\n",
    "        else:\n",
    "            print(f\"{package_name} | 0 matches in search\")\n",
    "    else:\n",
    "        print(f\"{url} | Non-200 response\")\n",
    "        return None\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Maven: 100\n",
      "net.ripe.rpki:rpki-validator-3 | 0 matches in search\n",
      "org.apache.kafka:kafka | 0 matches in search\n",
      "Failure in file request: https://search.maven.org/remotecontent?filepath=ca/uhn/hapi/fhir/hapi-fhir-base/6.2.4/hapi-fhir-base-6.2.4.pom | mismatched tag: line 6, column 2\n"
     ]
    }
   ],
   "source": [
    "maven_missing = ghsa_missing_GH_repo[ghsa_missing_GH_repo['package_ecosystem']==\"Maven\"][:100]\n",
    "\n",
    "maven_missing = maven_missing.drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "print(f\"Missing Maven: {maven_missing.id.nunique()}\")\n",
    "\n",
    "maven_missing['temp_repo'] = maven_missing.apply(\n",
    "    lambda x: maven_search(x['package_name']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found GH Repo: 18\n",
      "No GH Repo: 82\n",
      "\n",
      "Saving info for 18 Maven GHSAs | ./missing_GH_info/maven_20230111.csv\n"
     ]
    }
   ],
   "source": [
    "# check if github is in link\n",
    "maven_missing[\"github_repo\"] = maven_missing.apply(\n",
    "    lambda x: x['temp_repo'] if 'github.com' in str(x['temp_repo']) else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# cleaning the scm links\n",
    "maven_missing[\"github_repo\"] = maven_missing.apply(\n",
    "    lambda x: f\"https://github.com/{x['github_repo'].split('@github.com:')[-1]}\" if '@github.com:' in str(x['github_repo']) else x['github_repo'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# remove .git from link\n",
    "maven_missing[\"github_repo\"] = maven_missing.apply(\n",
    "    lambda x: x['github_repo'].replace('.git', '') if x['github_repo'] != None else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"Found GH Repo: {maven_missing[maven_missing['github_repo'].notna()].id.nunique()}\")\n",
    "print(f\"No GH Repo: {maven_missing[maven_missing['github_repo'].isna()].id.nunique()}\\n\")\n",
    "\n",
    "# save data to a CSV\n",
    "maven_missing_final = maven_missing[[\"id\",\"package_ecosystem\",\n",
    "                                 \"package_name\", \"github_repo\"]].drop_duplicates()\n",
    "\n",
    "# when saving data only keep the ones we found a GH repo for\n",
    "maven_missing_final = maven_missing_final[maven_missing_final['github_repo'].notna()].reset_index(drop=True)\n",
    "\n",
    "print(f\"Saving info for {maven_missing_final.id.nunique()} Maven GHSAs | ./missing_GH_info/maven_20230111.csv\")\n",
    "\n",
    "maven_missing_final.to_csv(f\"./missing_GH_info/maven_20230111.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPM Finds\n",
    "\n",
    "* We can directly hit the NPM registry at https://registry.npmjs.org/{package_name}\n",
    "    * The response is a JSON that we can parse for the repository url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def npm_registry_source_code(package_name: str) -> str:\n",
    "    \"\"\"Obtain the repository git link\n",
    "\n",
    "    Args:\n",
    "        package_name (str): Target package name\n",
    "\n",
    "    Returns:\n",
    "        str: Git repo link\n",
    "    \"\"\"\n",
    "    # set URL\n",
    "    url = f\"https://registry.npmjs.org/{package_name}\"\n",
    "    \n",
    "    response = requests.get(url)\n",
    "    response.close()\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        temp = response.json()\n",
    "        try:\n",
    "            repo = temp['repository']['url']\n",
    "            repo_match = re.findall(\"(?=github.com\\/)(.*)(\\/)(.*)\", repo.strip('.git'))\n",
    "            if len(repo_match) > 0:\n",
    "                repo_clean = ''.join(repo_match[0])\n",
    "                repo_clean = f\"https://{repo_clean}\"\n",
    "                return repo_clean\n",
    "        except Exception as e:\n",
    "            # print(f\"{url} | {str(e)}\")\n",
    "            return None\n",
    "    else:\n",
    "        print(f\"{url} | Non-200 response\")\n",
    "        return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing NPM: 100\n"
     ]
    }
   ],
   "source": [
    "npm_missing = ghsa_missing_GH_repo[ghsa_missing_GH_repo['package_ecosystem']==\"npm\"]\n",
    "\n",
    "npm_missing = npm_missing.drop_duplicates().reset_index(drop=True)[:100]\n",
    "\n",
    "print(f\"Missing NPM: {npm_missing.id.nunique()}\")\n",
    "\n",
    "npm_missing['temp_repo'] = npm_missing.apply(\n",
    "    lambda x: npm_registry_source_code(x['package_name']),\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting 52 GHSAs to None due to security-holder from NPM\n",
      "\n",
      "Found GH Repo for NPM GHSAs: 26\n",
      "No GH Repo for NPM GHSAs: 74\n",
      "\n",
      "Saving info for 26 NPM GHSAs | ./missing_GH_info/npm_20230111.csv\n"
     ]
    }
   ],
   "source": [
    "# with NPM, malicious packages have been removed and replaced with \"https://github.com/npm/security-holder\"\n",
    "print(f\"Setting {npm_missing[npm_missing['temp_repo']=='https://github.com/npm/security-holder'].id.nunique()}\"\n",
    "      f\" GHSAs to None due to security-holder from NPM\\n\")\n",
    "\n",
    "npm_missing[\"github_repo\"] = npm_missing.apply(\n",
    "    lambda x: None if x['temp_repo'] == \"https://github.com/npm/security-holder\" else x['temp_repo'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "print(f\"Found GH Repo for NPM GHSAs: {npm_missing[npm_missing['github_repo'].notna()].id.nunique()}\")\n",
    "print(f\"No GH Repo for NPM GHSAs: {npm_missing[npm_missing['github_repo'].isna()].id.nunique()}\\n\")\n",
    "\n",
    "# save data to a CSV\n",
    "npm_missing_final = npm_missing[[\"id\",\"package_ecosystem\",\n",
    "                                 \"package_name\", \"github_repo\"]].drop_duplicates()\n",
    "\n",
    "# when saving data only keep the ones we found a GH repo for\n",
    "npm_missing_final = npm_missing_final[npm_missing_final['github_repo'].notna()].reset_index(drop=True)\n",
    "\n",
    "print(f\"Saving info for {npm_missing_final.id.nunique()} NPM GHSAs | ./missing_GH_info/npm_20230111.csv\")\n",
    "\n",
    "npm_missing_final.to_csv(f\"./missing_GH_info/npm_20230111.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyPI Finds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    response = requests.get(url=url)  # request response from url\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "class GetPackageProjectLinks():\n",
    "    def __init__(self, package_name):\n",
    "        self.package_name = package_name\n",
    "        self.home_page = None\n",
    "        self.bug_tracker = None\n",
    "        self.documentation = None\n",
    "        self.source_code = None\n",
    "        self.url = f\"https://pypi.org/project/{self.package_name}/\"\n",
    "\n",
    "        soup = get_soup(self.url)\n",
    "        table = soup.find_all(\"div\", attrs={\"class\": \"sidebar-section\"})\n",
    "\n",
    "        for each in table:\n",
    "            for row in each.find_all(\"a\"):\n",
    "                if row.text.strip() == \"Homepage\":\n",
    "                    self.home_page = row.get(\"href\")\n",
    "                if row.text.strip() == \"Bug Tracker\":\n",
    "                    self.bug_tracker = row.get(\"href\")\n",
    "                if row.text.strip() == \"Documentation\":\n",
    "                    self.documentation = row.get(\"href\")\n",
    "                if row.text.strip() == \"Source\":\n",
    "                    self.source_code = row.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pypi_missing = advisories_missing_GH_repo[advisories_missing_GH_repo['ecosystem']==\"PyPI\"]\n",
    "\n",
    "pypi_missing = pypi_missing[['id', 'package_name']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "pypi_missing[\"links\"] = pypi_missing.apply(\n",
    "    lambda x: GetPackageProjectLinks(package_name=x['package_name']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# set source code\n",
    "pypi_missing[\"source_code\"] = pypi_missing.apply(\n",
    "    lambda x: x['links'].source_code,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# set home page link\n",
    "pypi_missing[\"home_page\"] = pypi_missing.apply(\n",
    "    lambda x: x['links'].home_page,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# check if github url in either source_code or home_page\n",
    "pypi_missing[\"github_repo\"] = pypi_missing.apply(\n",
    "    lambda x: x['source_code'] if 'github.com/' in str(x['source_code']) else None,\n",
    "    axis=1\n",
    ")\n",
    "# check home_page for github link\n",
    "pypi_missing[\"github_repo\"] = pypi_missing.apply(\n",
    "    lambda x: x['home_page'] if 'github.com/' in str(x['home_page']) else x['github_repo'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found GH Repo: {pypi_missing[pypi_missing['github_repo'].notna()].id.nunique()}\")\n",
    "print(f\"No GH Repo: {pypi_missing[pypi_missing['github_repo'].isna()].id.nunique()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Packagist Finds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    response = requests.get(url=url)  # request response from url\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "class PackagistProjectLinks():\n",
    "    def __init__(self, package_name):\n",
    "        self.package_name = package_name\n",
    "        self.canonical_repo = None\n",
    "        self.home_page = None\n",
    "        self.source_code = None\n",
    "        self.issues = None\n",
    "        self.url = f\"https://packagist.org/packages/{self.package_name}\"\n",
    "\n",
    "        soup = get_soup(self.url)\n",
    "        table = soup.find_all(\"div\", attrs={\"class\": \"row package-aside\"})\n",
    "\n",
    "        for each in table:\n",
    "            for row in each.find_all(\"a\"):\n",
    "                if row.get(\"title\") == \"Canonical Repository URL\":\n",
    "                    self.canonical_repo = row.text.strip()\n",
    "                if row.text.strip() == \"Homepage\":\n",
    "                    self.home_page = row.get(\"href\")\n",
    "                if row.text.strip() == \"Source\":\n",
    "                    self.source_code = row.get(\"href\")\n",
    "                if row.text.strip() == \"Issues\":\n",
    "                    self.issues = row.get(\"href\")\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "packagist_missing = advisories_missing_GH_repo[advisories_missing_GH_repo['ecosystem']==\"Packagist\"]\n",
    "\n",
    "packagist_missing = packagist_missing[['id', 'package_name']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "packagist_missing[\"links\"] = packagist_missing.apply(\n",
    "    lambda x: PackagistProjectLinks(package_name=x['package_name']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# set source code\n",
    "packagist_missing[\"source_code\"] = packagist_missing.apply(\n",
    "    lambda x: x['links'].source_code,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# set home page link\n",
    "packagist_missing[\"home_page\"] = packagist_missing.apply(\n",
    "    lambda x: x['links'].home_page,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# set canonical_repo link\n",
    "packagist_missing[\"canonical_repo\"] = packagist_missing.apply(\n",
    "    lambda x: x['links'].canonical_repo,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# check if github url in either source_code or home_page\n",
    "packagist_missing[\"github_repo\"] = packagist_missing.apply(\n",
    "    lambda x: x['source_code'] if 'github.com/' in str(x['source_code']) else None,\n",
    "    axis=1\n",
    ")\n",
    "# check home_page for github link\n",
    "packagist_missing[\"github_repo\"] = packagist_missing.apply(\n",
    "    lambda x: x['home_page'] if 'github.com/' in str(x['home_page']) else x['github_repo'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# check home_page for github link\n",
    "packagist_missing[\"github_repo\"] = packagist_missing.apply(\n",
    "    lambda x: x['canonical_repo'] if 'github.com/' in str(x['canonical_repo']) else x['github_repo'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found GH Repo: {packagist_missing[packagist_missing['github_repo'].notna()].id.nunique()}\")\n",
    "print(f\"No GH Repo: {packagist_missing[packagist_missing['github_repo'].isna()].id.nunique()}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RubyGems Finds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    response = requests.get(url=url, headers=headers)  # request response from url\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "class RubyGemsProjectLinks():\n",
    "    def __init__(self, package_name):\n",
    "        self.package_name = package_name\n",
    "        self.home_page = None\n",
    "        self.source_code = None\n",
    "        self.issues = None\n",
    "        self.url = f\"https://rubygems.org/gems/{self.package_name}\"\n",
    "\n",
    "        soup = get_soup(self.url)\n",
    "        table = soup.find_all(\"div\", attrs={\"class\": \"gem__aside l-col--r--pad\"})\n",
    "\n",
    "        for each in table:\n",
    "            for row in each.find_all(\"a\"):\n",
    "                if row.text.strip() == \"Homepage\":\n",
    "                    self.home_page = row.get(\"href\")\n",
    "                    if 'github.com/' in str(self.home_page):\n",
    "                        # some link cleaning\n",
    "                        temp_home = self.home_page.split(\"github.com/\")[-1].split('/')[:2]\n",
    "                        self.home_page = f\"https://github.com/{'/'.join(temp_home)}\"\n",
    "                        \n",
    "                if row.text.strip() == \"Source Code\":\n",
    "                    self.source_code = row.get(\"href\")\n",
    "                    if 'github.com/' in str(self.source_code):\n",
    "                        # some link cleaning\n",
    "                        temp_source = self.source_code.split(\"github.com/\")[-1].split('/')[:2]\n",
    "                        self.source_code = f\"https://github.com/{'/'.join(temp_source)}\"\n",
    "                        \n",
    "                if row.text.strip() == \"Bug Tracker\":\n",
    "                    self.issues = row.get(\"href\")\n",
    "                    if 'github.com/' in str(self.issues):\n",
    "                        # some link cleaning\n",
    "                        temp_issues = self.issues.split(\"github.com/\")[-1].split('/')[:2]\n",
    "                        self.issues = f\"https://github.com/{'/'.join(temp_issues)}\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rubygems_missing = advisories_missing_GH_repo[advisories_missing_GH_repo['ecosystem']==\"RubyGems\"]\n",
    "\n",
    "rubygems_missing = rubygems_missing[['id', 'package_name']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "rubygems_missing[\"links\"] = rubygems_missing.apply(\n",
    "    lambda x: RubyGemsProjectLinks(package_name=x['package_name']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# set source code\n",
    "rubygems_missing[\"source_code\"] = rubygems_missing.apply(\n",
    "    lambda x: x['links'].source_code,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# set home page link\n",
    "rubygems_missing[\"home_page\"] = rubygems_missing.apply(\n",
    "    lambda x: x['links'].home_page,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# set issues link\n",
    "rubygems_missing[\"issues\"] = rubygems_missing.apply(\n",
    "    lambda x: x['links'].issues,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# check home_page for github link\n",
    "rubygems_missing[\"github_repo\"] = rubygems_missing.apply(\n",
    "    lambda x: x['home_page'] if 'github.com/' in str(x['home_page']) else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# check home_page for github link\n",
    "rubygems_missing[\"github_repo\"] = rubygems_missing.apply(\n",
    "    lambda x: x['issues'] if 'github.com/' in str(x['issues']) else x['github_repo'],\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# check if github url in either source_code or home_page\n",
    "rubygems_missing[\"github_repo\"] = rubygems_missing.apply(\n",
    "    lambda x: x['source_code'] if 'github.com/' in str(x['source_code']) else x['github_repo'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found GH Repo: {rubygems_missing[rubygems_missing['github_repo'].notna()].id.nunique()}\")\n",
    "print(f\"No GH Repo: {rubygems_missing[rubygems_missing['github_repo'].isna()].id.nunique()}\")\n",
    "\n",
    "rubygems_missing.to_csv(f\"./data/final_data/missing_GH_info/advisories_rubygems_20221204.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NuGet Finds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    response = requests.get(url=url, headers=headers)  # request response from url\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "class NuGetProjectLinks():\n",
    "    def __init__(self, package_name):\n",
    "        self.package_name = package_name\n",
    "        self.home_page = None\n",
    "        self.source_code = None\n",
    "        self.url = f\"https://www.nuget.org/packages/{self.package_name}\"\n",
    "\n",
    "        soup = get_soup(self.url)\n",
    "        \n",
    "        if \"Rate limit is exceeded\" in soup.text:\n",
    "            print(soup.text)\n",
    "            print(f\"Sleeping for 60 seconds...\")\n",
    "            time.sleep(60)\n",
    "            # get soup again\n",
    "            soup = get_soup(self.url)\n",
    "            \n",
    "        table = soup.find_all(\"div\", attrs={\"class\": \"sidebar-section\"})\n",
    "        \n",
    "        for each in table:\n",
    "            for row in each.find_all(\"a\"):\n",
    "                if row.text.strip() == \"Project website\":\n",
    "                    self.home_page = row.get(\"href\")\n",
    "                        \n",
    "                if row.text.strip() == \"Source repository\":\n",
    "                    self.source_code = row.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nuget_missing = advisories_missing_GH_repo[advisories_missing_GH_repo['ecosystem']==\"NuGet\"]\n",
    "\n",
    "nuget_missing = nuget_missing[['id', 'package_name']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "nuget_missing[\"links\"] = nuget_missing.apply(\n",
    "    lambda x: NuGetProjectLinks(package_name=x['package_name']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# set source code\n",
    "nuget_missing[\"source_code\"] = nuget_missing.apply(\n",
    "    lambda x: x['links'].source_code,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# set home page link\n",
    "nuget_missing[\"home_page\"] = nuget_missing.apply(\n",
    "    lambda x: x['links'].home_page,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# check home_page for github link\n",
    "nuget_missing[\"github_repo\"] = nuget_missing.apply(\n",
    "    lambda x: x['home_page'] if 'github.com/' in str(x['home_page']) else None,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# check if github url in either source_code or home_page\n",
    "nuget_missing[\"github_repo\"] = nuget_missing.apply(\n",
    "    lambda x: x['source_code'] if 'github.com/' in str(x['source_code']) else x['github_repo'],\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found GH Repo: {nuget_missing[nuget_missing['github_repo'].notna()].id.nunique()}\")\n",
    "print(f\"No GH Repo: {nuget_missing[nuget_missing['github_repo'].isna()].id.nunique()}\")\n",
    "\n",
    "nuget_missing.to_csv(f\"./data/final_data/missing_GH_info/advisories_nuget_20221204.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Go Finds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_soup(url):\n",
    "    headers = {'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/39.0.2171.95 Safari/537.36'}\n",
    "    response = requests.get(url=url, headers=headers)  # request response from url\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "    return soup\n",
    "\n",
    "\n",
    "class GoProjectLinks():\n",
    "    def __init__(self, package_name):\n",
    "        self.package_name = package_name\n",
    "        self.source_code = None\n",
    "        self.url = f\"https://pkg.go.dev/{self.package_name}\"\n",
    "\n",
    "        soup = get_soup(self.url)\n",
    "            \n",
    "        table = soup.find_all(\"div\", attrs={\"class\": \"UnitMeta-repo\"})\n",
    "        \n",
    "        for each in table:\n",
    "            for row in each.find_all(\"a\"):\n",
    "                self.source_code = row.get(\"href\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "go_missing = advisories_missing_GH_repo[advisories_missing_GH_repo['ecosystem']==\"Go\"]\n",
    "\n",
    "go_missing = go_missing[['id', 'package_name']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "go_missing[\"links\"] = go_missing.apply(\n",
    "    lambda x: GoProjectLinks(package_name=x['package_name']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# set source code\n",
    "go_missing[\"source_code\"] = go_missing.apply(\n",
    "    lambda x: x['links'].source_code,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# check if github url in either source_code or home_page\n",
    "go_missing[\"github_repo\"] = go_missing.apply(\n",
    "    lambda x: x['source_code'] if 'github.com/' in str(x['source_code']) else None,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found GH Repo: {go_missing[go_missing['github_repo'].notna()].id.nunique()}\")\n",
    "print(f\"No GH Repo: {go_missing[go_missing['github_repo'].isna()].id.nunique()}\")\n",
    "\n",
    "go_missing.to_csv(f\"./data/final_data/missing_GH_info/advisories_go_20221204.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crates.IO Finds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CratesProjectLinks():\n",
    "    def __init__(self, package_name):\n",
    "        self.package_name = package_name\n",
    "        self.source_code = None\n",
    "        \n",
    "        # we can use a direct API here\n",
    "        self.url = f\"https://crates.io/api/v1/crates/{self.package_name}\"\n",
    "\n",
    "        response = requests.get(url=self.url)\n",
    "        \n",
    "        if response.status_code == 200:\n",
    "            self.source_code = response.json()[\"crate\"][\"repository\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crates_missing = advisories_missing_GH_repo[advisories_missing_GH_repo['ecosystem']==\"crates.io\"]\n",
    "\n",
    "crates_missing = crates_missing[['id', 'package_name']].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "crates_missing[\"links\"] = crates_missing.apply(\n",
    "    lambda x: CratesProjectLinks(package_name=x['package_name']),\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# set source code\n",
    "crates_missing[\"source_code\"] = crates_missing.apply(\n",
    "    lambda x: x['links'].source_code,\n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# check if github url in either source_code or home_page\n",
    "crates_missing[\"github_repo\"] = crates_missing.apply(\n",
    "    lambda x: x['source_code'] if 'github.com/' in str(x['source_code']) else None,\n",
    "    axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Found GH Repo: {crates_missing[crates_missing['github_repo'].notna()].id.nunique()}\")\n",
    "print(f\"No GH Repo: {crates_missing[crates_missing['github_repo'].isna()].id.nunique()}\")\n",
    "\n",
    "crates_missing.to_csv(f\"./data/final_data/missing_GH_info/advisories_crates_20221204.csv\", encoding='utf-8', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6669e0aea01684a9d5dc4ed262ee49a72e00b93c6432aeb9e9912f63b574a39e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
